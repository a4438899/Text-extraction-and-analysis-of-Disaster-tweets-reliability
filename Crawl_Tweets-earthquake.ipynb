{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawl_Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.twitter.com/oauth/authorize?oauth_token=bnuphgAAAAABJO56AAABdXLjgY8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import spacy\n",
    "from datetime import datetime\n",
    "\n",
    "consumer_key = \"bqmtYoayzY4XzADvxT2MS8Ddw\"\n",
    "consumer_secret = \"XmyPAPAYSZEchlRsZ8PcucteMLfefcP04uzylUHZwPFFmzbahi\"\n",
    "access_token = \"1317050431814578176-SubCh14KGYANuAdZsDAWef0GO26Doz\"\n",
    "access_token_secret = \"kpgbjaljF1fhGhLXhkop5fAKbcf5EKu3EhioBpAXgwcPI\"\n",
    "# Creating the authentication object\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "\n",
    "# Setting access token and secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# Creating the API object while passing in auth information\n",
    "#api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "\n",
    "try:\n",
    "    redirect_url = auth.get_authorization_url()\n",
    "    print(redirect_url)\n",
    "except tweepy.TweepError:\n",
    "    print ('Error! Failed to get request token.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_words:  \"earthquake\" OR #earthquake -filter:retweets\n",
      "(1500, 3)\n",
      "                       user                                              tweet                      location\n",
      "0       Shamkhal Galandarov  Your forests were in fire - we prayed. \\nYour ...                              \n",
      "1                 ghou-li‚ÇÜ‚Çâ  apparently an earthquake happened in my area w...  7TEEN | pfp: @CherryitaDraws\n",
      "2                      Regi  @mrnesflrntn @azithought @caaaamsssss Earthqua...                              \n",
      "3        James Chikonamombe  @Sir_Geechie @AfroN8V @MimiReeds Haitians were...                   Oakland, Ca\n",
      "4          shreeni | mina üìå             @joshualogs there was an earthquake :(                     16 ‚òÜ desi\n",
      "5  Letran SHS Fourth Estate  BREAKING: A magnitude 4.5 earthquake hits Mabi...                              \n",
      "6                     raven  fortunately the earthquake wasnt that strong b...   old hollywood, bowie & film\n",
      "7                     raven  how is it that my country is dealing w a pande...   old hollywood, bowie & film\n",
      "8                   Ÿãsofia‚Å∑  it rained then an earthquake happened ,, what ...                     she / her\n",
      "9              ·¥Æ·¥±ryonia‚Å∑ ê§Äü•Ä  they say, we had an earthquake??? please, take...                       she/her \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "today_date = datetime.today().strftime('%m-%d')\n",
    "constituency = ['earthquake']\n",
    "query = ['\"earthquake\" OR #earthquake']\n",
    "output_file = [\"earthquake\" +today_date +\".csv\"]\n",
    "\n",
    "for idx, search_words in enumerate(query):\n",
    "    #retweet filtered\n",
    "    search_words = search_words + \" -filter:retweets\"\n",
    "    print(\"search_words: \", search_words)\n",
    "    num_records = 1500\n",
    "    #Call the tweepy API, just put 2020 whole year, though tweepy only support past 7 days scraping\n",
    "    tweets = tweepy.Cursor(api.search, q=search_words, lang=\"en\",\n",
    "                tweet_mode=\"extended\", since = \"2020-01-01\",\n",
    "                           until = \"2020-12-31\").items(num_records)\n",
    "    dlist = [[t.user.name,t.full_text,t.user.location] for t in tweets]\n",
    "    df = pd.DataFrame(data=dlist,columns=['user','tweet','location'])\n",
    "    with pd.option_context('expand_frame_repr', False):\n",
    "        print(df.shape)\n",
    "        print(df[['user', 'tweet','location']].head(10), \"\\n\\n\")\n",
    "    df['keyword']=constituency[idx]\n",
    "    df.to_csv(output_file[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
