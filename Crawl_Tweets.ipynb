{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawl_Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.twitter.com/oauth/authorize?oauth_token=0M6tHAAAAAABJC6lAAABdXLgxXc\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import spacy\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "consumer_key = 'YVb9YcUHeiC8PzpnRSyQhvHAg'\n",
    "consumer_secret = 'EAWICA3YFu2YcT7kQ6kMbDIJnJbcnKSAxI6Oi5wHfTTUIx7fqS'\n",
    "access_token = '2208154789-CKlKnaaTmPBOoe9KOQ8NH1Qngf9LagwYYj2EiIH'\n",
    "access_token_secret = '3R7JRNJZdAYczEWnB3fbPkvwZKjErE3KYeE9qIo52cjuF'\n",
    "# Creating the authentication object\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "\n",
    "# Setting access token and secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "# Creating the API object while passing in auth information\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "#api = tweepy.API(auth)\n",
    "\n",
    "try:\n",
    "    redirect_url = auth.get_authorization_url()\n",
    "    print(redirect_url)\n",
    "except tweepy.TweepError:\n",
    "    print ('Error! Failed to get request token.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search_words:  arson OR \"#arson\" -filter:retweets\n",
      "(1500, 3)\n",
      "                              user                                              tweet              location\n",
      "0                       James Keay  I guess that‚Äôs what the riots, arson and murde...        Boston, MA USA\n",
      "1  Random üê∏üéÉ||DUCKTALES SPOILERS||            @Iaunchdad i‚Äôm going to commit arson /j                      \n",
      "2                   Snake Plissken  @kmbecker13 @dont_growup @Venice311 How can yo...                      \n",
      "3                 Connie Hilarides       @FreyjaErlings Bastard cop arson. Sounds fun           Redmond, WA\n",
      "4                      missiongirl  something very weird is happening. there are m...                      \n",
      "5                  Shane B. Murphy  #Philadelphia\\n-MORE LOOTING-\\n10 Cars just br...      Lincoln, Ontario\n",
      "6                          Mistrex  @ggneedshelp @malleksaturn DID I HEAR ARSON\\nA...                      \n",
      "7                       ella arson  @WICKEDBWNY Oh hell Yes! The work has just beg...                      \n",
      "8                        RonniSalt  I'm not blind to the insidious subversiveness ...  Slightly to the left\n",
      "9      üåßüåøFelix/Fei misses Illumiüåøüåß  Goodnight moots! I will now dream of arson and...            üÉèClowntown \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "today_date = datetime.today().strftime('%m-%d')\n",
    "\n",
    "constituency = ['arson']\n",
    "\n",
    "query = ['arson OR \"#arson\"']\n",
    "\n",
    "output_file = [\"twitter\" +today_date + \"arson.csv\"]\n",
    "\n",
    "for idx, search_words in enumerate(query):\n",
    "    #retweet filtered\n",
    "    search_words = search_words + \" -filter:retweets\"\n",
    "    print(\"search_words: \", search_words)\n",
    "    num_records = 1500\n",
    "\n",
    " \n",
    "\n",
    "    #Call the tweepy API, just put 2020 whole year, though tweepy only support past 7 days scraping\n",
    "    tweets = tweepy.Cursor(api.search, q=search_words, lang=\"en\",\n",
    "                tweet_mode=\"extended\", since = \"2020-01-01\", until = \"2020-12-31\").items(num_records)\n",
    "\n",
    " \n",
    "\n",
    "    dlist = [[t.user.name,t.full_text,t.user.location] for t in tweets]\n",
    "    df = pd.DataFrame(data=dlist,columns=['user','tweet','location'])\n",
    "    with pd.option_context('expand_frame_repr', False):\n",
    "        print(df.shape)\n",
    "        print(df[['user', 'tweet','location']].head(10), \"\\n\\n\")\n",
    "\n",
    " \n",
    "\n",
    "    df['keyword']=constituency[idx]\n",
    "\n",
    " \n",
    "\n",
    "    df.to_csv(output_file[idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
